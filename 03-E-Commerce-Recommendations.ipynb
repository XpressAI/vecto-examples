{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1676154",
   "metadata": {},
   "source": [
    "# 03 E-Commerce Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40651c",
   "metadata": {},
   "source": [
    "Product recommendations powered by vector search help E-commerce merchants offer relevant and personalized shopping experiences, improving clients' experience site-wide.\n",
    "\n",
    "Throughout this tutorial, we will guide you through the journey to create a basic E-commerce recommendations application using Vecto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0114a",
   "metadata": {},
   "source": [
    "## Setting up Vecto Working Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ftfy tqdm requests pillow ipywidgets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af32b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from ipywidgets import interact_manual, IntSlider, FileUpload\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import io\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f99b65",
   "metadata": {},
   "source": [
    "## Creating Vector Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ce834",
   "metadata": {},
   "source": [
    "1. Access the Vecto login page at <[Vecto Login](https://app.vecto.ai/login.xhtml)>, insert your *Username* and *Password* and click Sign In. \n",
    "   \n",
    "2. From the admin page sidebar, select the **Dashboard** tab and click on *Create new vector space*. Fill in the Vector Space name; in this case, we will call it `e_commerce_recommendation`. You will then be able to choose a `vectorization model`. As we are going to work with both images and text, choose the [CLIP](https://github.com/openai/CLIP) model. Finally, click the `Create Vector Space` button. You can view your Vector Space details by clicking on the Vector Space name in the Vector Spaces list. Take note on your Vector Space ID to use in a later step. \n",
    "    \n",
    "3. In order to access the vector space, we will need to create a Vector Space authentication token. Click on the **Tokens** tab in the sidebar, set the token name to `e_commerce_recommendation_token`, and then select the Vector Space `e_commerce_recommendation` that we created earlier, click on `Create User Token`. Click on your token name in the list to view it. This token will be used to authenticate access to Vecto servers. Copy the token to use in the next step. Here we go! Now you have your first Vector Space.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8d45924",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://docs.vecto.ai/img/docs/user-guide/Hello_world/login_vecto.gif\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944cc04e",
   "metadata": {},
   "source": [
    "## Add and Ingest Data into Vector Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2852fe2",
   "metadata": {},
   "source": [
    " To start, let's initialize the Vecto API end-point and pass our `e_commerce_recommendation` Vector Space ID and authentication token. Copy the below cell into your notebook 2nd cell and insert the values for the `token` and `vecto_space_id`, then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba002a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecto_base_url =\"https://api.vecto.ai/api/v0\"\n",
    "token = \"\"\n",
    "vector_space_id = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df18c7e7",
   "metadata": {},
   "source": [
    "Please note that the Vector Space ID and token are unique for every Vector Space. You refer to the [previous step](#creating-vector-space) if you can not find your `e_commerce_recommendation` Vector Space ID or token. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f83adc",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645da28e",
   "metadata": {},
   "source": [
    "In this Tutorial, we are using the [Flipkart Products dataset from Kaggle](https://www.kaggle.com/datasets/PromptCloudHQ/flipkart-products). This dataset has details for around 20,000 different product listings on FlipKart website. \n",
    "\n",
    "To proceed, you may manually download the dataset and place it in the working directory, or use Kaggle API to download it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd51ae",
   "metadata": {},
   "source": [
    "If you would like to use Kaggle, you may follow the [following steps](https://www.kaggle.com/general/74235):\n",
    "1. Go to your account, Scroll to API section and Click Expire API Token to remove previous tokens if you've created one before.\n",
    "2. Click on Create New API Token - It will download kaggle.json file on your machine.\n",
    "3. Place kaggle.json in the current Jupyter working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac2b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run these two cells if you are using google colab\n",
    "# from google.colab import files\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864cd5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir .kaggle\n",
    "# ! cp kaggle.json .kaggle/\n",
    "# ! chmod 600 .kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle datasets download \"PromptCloudHQ/flipkart-products\"\n",
    "! unzip flipkart-products.zip -d ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97138cc",
   "metadata": {},
   "source": [
    "Now your working directory should look like this:\n",
    "```\n",
    "|__vecto_ecommerce_demo\n",
    "    |__requirements.txt\n",
    "    |__e_commerce_demo.ipynb\n",
    "    |__flipkart_com-ecommerce_sample.csv\n",
    "```\n",
    "Now, let's read the dataset's `.csv` file. Here, we are interested in vectorizing the `product_name` and `description` columns; we will drop any product without `product_name` and `description` and concatenate the texts in both columns into a new `product_details` column. Additionally, we will convert the `image` column to a list of URLs for easier online retrieval of the product images. Finally, we will collect the `product_details` column and the indexes into Python lists:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e802c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = pd.read_csv('flipkart_com-ecommerce_sample.csv').dropna(subset=['product_name','description'])\n",
    "text_data['product_details'] = text_data['product_name'].astype(str) +\" \"+ text_data['description'].astype(str) \n",
    "raw_text_list = text_data['product_details'].tolist()\n",
    "index_list = text_data.index.tolist()\n",
    "text_data[\"image\"] = text_data[\"image\"].apply(lambda x: json.loads(x) if type(x) == str else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75697e6b",
   "metadata": {},
   "source": [
    "The text descriptions in the `raw_text_list` require some pre-processing to remove any special characters or extra spaces between the words. We will use the following code to achieve that:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70dc686",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "for i in raw_text_list:\n",
    "    text = (i.rstrip('\\n')).replace('\\n','')\n",
    "    text = (text.rstrip('\\t')).replace('\\t','')\n",
    "    text = re.sub('[^\\w]',' ', text)\n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    text_list.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e24ab5",
   "metadata": {},
   "source": [
    "### Vectorize text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad54cd",
   "metadata": {},
   "source": [
    "To ingest the texts descriptions in the `text_list` list into our `e_commerce_recommendation` Vector Space, we will need a few helper functions to split the texts ingesting process into batches, let's add the two functions `ingest_text_batch` and `ingest_all_text` to our `e_commerce_demo` notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953fa892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_text_batch(batch_path_list,batch_text_list):\n",
    "    data = {'vector_space_id': vector_space_id, 'data': [], 'modality': 'TEXT'}\n",
    "    files = []\n",
    "    for path in batch_path_list:\n",
    "        data['data'].append(path)\n",
    "    result = requests.post(\"%s/index\" % vecto_base_url,\n",
    "                  data=data,\n",
    "                  files=[('input', ('_', f, '_')) for f in batch_text_list],\n",
    "                  headers={\"Authorization\":\"Bearer %s\" %token})\n",
    "\n",
    "    for f in files:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbd568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_all_text(path_list,text_list, batch_size=64):\n",
    "    batch_count = math.ceil(len(path_list) / batch_size)\n",
    "    batches_path = [path_list[i * batch_size: (i + 1) * batch_size] for i in range(batch_count)]\n",
    "    batches_text = [text_list[i * batch_size: (i + 1) * batch_size] for i in range(batch_count)]\n",
    "    for batch,text in tqdm(zip(batches_path,batches_text), total = len(batches_path)):\n",
    "        ingest_text_batch(batch,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c039cf",
   "metadata": {},
   "source": [
    "The batch size determines the number of texts ingested in each batch. Here, we set the batch size to `256` to speed up the initial ingest process. However, batch size could be set to any other integer value, even just `1`, as this is merely depending on the dataset type and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816da1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_all_text(index_list,text_list,batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec8ac6",
   "metadata": {},
   "source": [
    "Here we go! your current vector space holds all the products text descriptions embeddings. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f02137",
   "metadata": {},
   "source": [
    "## Vector Search image/text Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b2da6",
   "metadata": {},
   "source": [
    "After ingesting the dataset into the `e_commerce_recommendation` vector space, now let's try to perform a different type of vector search query using text or images. For that, we will use a few helper functions to handle the mentioned processes. Let's add these four functions `display_results`, `lookup`, `text_query`, and`image_query` to our `e_commerce_demo` notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results):\n",
    "    output = []\n",
    "    for result in results:\n",
    "        output.append(\"Similarity: %s\" % result['similarity'])\n",
    "        image = text_data['image'][int(result['data'])][0]\n",
    "        image = HTML('<img src=%s width=\"300\" height=\"500\">'% image)\n",
    "        output.append(image)\n",
    "        text = text_data['product_details'][int(result['data'])]\n",
    "        output.append(text)\n",
    "    display(*output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d36bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(f, modality, top_k):\n",
    "    result = requests.post(\"%s/lookup\" % vecto_base_url,\n",
    "                           data={'vector_space_id': vector_space_id, 'modality': modality, 'top_k': top_k},\n",
    "                           files={'query': f},\n",
    "                           headers={\"Authorization\":\"Bearer %s\" %token})\n",
    "\n",
    "    results = result.json()['results']\n",
    "    display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c715fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_query(query, top_k=10):\n",
    "    f = io.StringIO(query)\n",
    "    lookup(f, 'TEXT', top_k)\n",
    "\n",
    "def image_query(query, top_k=10):\n",
    "    f = io.BytesIO(query[0]['content'])\n",
    "    lookup(f, 'IMAGE', top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0434c2",
   "metadata": {},
   "source": [
    "Now all is ready to try a few vector search queries!\n",
    "\n",
    "First, let's start with some text queries. Using the interactive cell widget, you could:\n",
    "-  Type your query text in the available text box.\n",
    "-  Select the number of results with the highest search similarity to view `top_k`.\n",
    "\n",
    "For example, we will type *Round Neck T-Shirt* as our text query, and we expect the vector search to return more Round Neck T-Shirt products from the vector space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(text_query, query=\"Round Neck T-Shirt\", top_k=IntSlider(min=1, max=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e0f35",
   "metadata": {},
   "source": [
    "After you insert the above line into the `e_commerce_demo` notebook, you are expected to see the following output when you query *Round Neck T-Shirt* and set the *top_k* to 4. Click the `Run Interact` button to start the vector search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a26ad",
   "metadata": {},
   "source": [
    "Now similarly, let's try image queries. Using the interactive cell widget, you could:\n",
    "-  Upload your query image using the Upload button.\n",
    "-  Select the number of results with the highest search similarity to view `top_k`.\n",
    "\n",
    "As an example, we will upload an image of a black T-shirt downloaded from [Unsplash](https://unsplash.com/photos/6Nub980bI3I) as our image query. We would expect the vector search to return texts description for black T-shirt products from the vector space.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eea76249",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://docs.vecto.ai/img/docs/tutorial/e_commerce/image.jpg\"/  width=\"200\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edc0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(image_query, query=FileUpload(multiple=False), top_k=IntSlider(min=1, max=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c06dab",
   "metadata": {},
   "source": [
    "After you insert the above line into the `e_commerce_demo` notebook, you are expected to see the following widget, upload the image and click the `Run Interact` button to start the vector search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4e8b19",
   "metadata": {},
   "source": [
    "## Create a Vector Search Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93b0ea",
   "metadata": {},
   "source": [
    "A surprising property of vectors is that we can solve analogies with vector arithmetic. Taking `Summer is to Winter as is T-Shirt is to Sweater` as an analogy. We could use the vector difference **Summer vector - Winter vector** as an analogy vector to modify the vector search output for the *T-Shirt* query from returning more T-shirts products as we saw in the [earlier](#vector-search-imagetext-queries) to returning Winter clothes like sweaters instead. The overall arithmetic equation that governs such an analogy can be represented as follows:\n",
    "\n",
    "<p align=\"center\">\n",
    "Let <strong>Summer - Winter = T-Shirt - Sweater</strong> <br></br> \n",
    "Therefore, <strong>Winter - Summer + T-Shirt = Sweater</strong>\n",
    "</p>\n",
    "\n",
    "\n",
    "First, let's add this helper functions `analogy`,`text_analogy` and `image_analogy` to our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674728ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(query, start, end, modality, top_k):\n",
    "    result = requests.post(\"%s/analogy\" % vecto_base_url,\n",
    "                           data={'vector_space_id': vector_space_id, 'modality': modality, 'top_k': top_k},\n",
    "                           files={'query': query, 'from': start, 'to': end},\n",
    "                           headers={\"Authorization\":\"Bearer %s\" %token})\n",
    "\n",
    "    results = result.json()['results']\n",
    "    display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d499a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_analogy(query, start, end, top_k=10):\n",
    "    analogy(io.StringIO(query), io.StringIO(start), io.StringIO(end), 'TEXT', top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb73d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_analogy(query, start, end, top_k=10):\n",
    "    analogy(\n",
    "        io.BytesIO(query[0]['content']),\n",
    "        io.BytesIO(start[0]['content']),\n",
    "        io.BytesIO(end[0]['content']),\n",
    "        'IMAGE',\n",
    "        top_k\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c31ceb",
   "metadata": {},
   "source": [
    "Now all is ready, let's see if our analogy is working. \n",
    "\n",
    "First, let's start with some text analogy. Using the interactive cell widget, you could:\n",
    "-  Type analogy *start*, *end* and *query* text in the available text boxes.\n",
    "-  Select the number of results with the highest search similarity to view `top_k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(text_analogy, query=\"Round Neck T-Shirt\", start=\"summer\", end=\"winter\", top_k=IntSlider(min=1, max=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134a2ec",
   "metadata": {},
   "source": [
    "After you insert the above line into the `e_commerce_demo` notebook, you are expected to see the following output, set your **query** to *Round Neck T-Shirt* and set the analogy **start** and **end** to *summer* and *winter* respectively, click the `Run Interact` button to start the vector search with the analogy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9dcff1",
   "metadata": {},
   "source": [
    "Now similarly, let's construct the analogy using images. \n",
    "\n",
    "Using the interactive cell widget, you could:\n",
    "-  upload images for analogy *start*, *end* and *query* image using the upload button for each field.\n",
    "-  Select the number of results with the highest search similarity to view `top_k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(image_analogy, query=FileUpload(multiple=False), start=FileUpload(multiple=False), end=FileUpload(multiple=False), top_k=IntSlider(min=1, max=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb42fc",
   "metadata": {},
   "source": [
    "A simple exercise for you, insert the above line into the `e_commerce_demo` notebook. You are expected to see the following widget, construct your image analogy *Query, Start and End components* upload the images to the widget and click the `Run Interact` button to start your customized vector search analogy.\n",
    "\n",
    "\n",
    "That's it! In this tutorial, we have learned how to set up a Vecto working environment, create vector space using a given dataset, perform vector search queries, and construct a simple analogy.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8063cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
